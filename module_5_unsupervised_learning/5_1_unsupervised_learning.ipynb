{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Unsupervised Learning\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In earlier labs we learned how to use linear regression to study whether certain features are useful in predicting an observed outcome. Then we used ensemble methods to refine our predictions. \n",
    "\n",
    "In this notebook, we shift from prediction to pattern finding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll be doing in this notebook:\n",
    "-----\n",
    "\n",
    "1. Give a general introduction to unsupervised learning.\n",
    "1. Use k-means clustering as unsupervised learning technique.\n",
    "1. Load and explore a dataset.\n",
    "1. Find clusters with k-means algorithm.\n",
    "1. Evaluate our results with the Elbow method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Learning: Pattern finding in data üîç\n",
    "------\n",
    "\n",
    "Unsupervised Learning is the process of identifying patterns in a dataset. Identifying patterns is often an early step in understanding data. Unsupervised learning methods are a set of techniques designed to <i>explore</i> and find \"hidden structure\" rather than predict outcomes. \n",
    " \n",
    "Unsupervised learning does not require labeled data, therefore works for broader range of data. In fact, most data in the world is unlabelled. However, since there are no labels / correct answers there is not always a clear feedback to validate that the results are correct.\n",
    "\n",
    "Unsupervised Learning is also called Data Mining.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Types of Unsupervised Learning\n",
    "--------\n",
    "\n",
    "1. Dimension Reduction\n",
    "\n",
    "1. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Dimension Reduction?\n",
    "------\n",
    "\n",
    "Dimension reduction aims to find fewer number of features that be used to build a meaningful model. There are many reasons for reducing the number of features in a dataset, from avoiding overfitting to speeding up modeling fitting time.\n",
    "\n",
    "One of the most common dimension reduction techniques is Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Clustering?\n",
    "-----\n",
    "\n",
    "<center><img src=\"../images/clustering.jpeg\" width=\"700\"/></center>\n",
    "\n",
    "Clustering is what it sounds like: chunking your data into sub-groups (clusters) based on similar characteristics. Then these sub-groups are used for later analysis. Clustering is an intuitive to understand the various natural segments that make up the population of your data. Clustering typically makes it easier to visualizes your data.\n",
    "\n",
    "Clustering is also called [cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis), data segmentation, or data partitioning.\n",
    "\n",
    "We are going to focus on clustering for the rest of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to K-means Clustering\n",
    "------\n",
    "\n",
    "![](../images/k_means.png)\n",
    "\n",
    "K-means one of the most common clustering techniques. The goal of k-means is find a group of datapoints that close to each other (a cluster) and are far away from other datapoints (the other clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we do k-means clustering?\n",
    "-----\n",
    "\n",
    "Initially, datapoints are <i>randomly assigned</i> to a cluster. Then the center of each cluster is calculated.\n",
    "\n",
    "Then we alternate between two steps:\n",
    "\n",
    "1. Assignment step: Observations are assigned to a cluster where the center is closest to them.\n",
    "\n",
    "2. Update step: New center points of clusters are determined\n",
    "\n",
    "The process repeats until observations shuffle are long around to different cluasers anymore and the center of each cluster no longer moves.\n",
    "\n",
    "In other words, observations are constantly being reassigned to clusters until the distance between an observation and their closest center point is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means Example\n",
    "-----\n",
    "\n",
    "![](../images/left.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Fitting K-means to Kiva Data\n",
    "------\n",
    "\n",
    "Now we are going to fit k-means to <b>partition</b> or <b>segment</b> the Kiva data into clusters.\n",
    "\n",
    "Let's import the relevant packages to start coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to clear the variables from the namespace \n",
    "# to make sure our analysis starts from scratch each time.\n",
    "# -fs are arguments to keep history and ignore the confirmation prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# K-Means clustering algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "\n",
    "# Places the plots in the Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Keep everything visible\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Load and explore the data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the data is on the computer\n",
    "path = '../data/'\n",
    "\n",
    "filename = 'clean_data' # Has more columns\n",
    "\n",
    "# Load data into Pandas üêº\n",
    "df = pd.read_csv(path+filename+'.csv.zip',\n",
    "                 low_memory=False)\n",
    "\n",
    "# TODO: Remove these lines once this is added to feature engineering\n",
    "# Normalize column names\n",
    "df.columns = [c.lower().replace('.', '_').replace(' ', '_')\n",
    "              for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always good idea üí° to take a peak at the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[1]:,} columns in the dataframe.\")\n",
    "print(f\"There are {df.shape[0]:,} rows in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data set up, we can begin partitioning our data into clusters based only a few features. Let's think about how to choose these‚Ä¶\n",
    "\n",
    "As a potential borrower or lender, what would be interesting to explore? \n",
    "\n",
    "In the previous notebooks, we explored a number of interesting ideas, including:\n",
    "\n",
    "- How much a borrower should ask to borrow\n",
    "- The time it takes to fund a loan\n",
    "- What features can influence the loan amount\n",
    "- If we partition borrowers into distinct groups based on how quickly they can fund a loan, will we be able to learn anything about these groups of borrowers?\n",
    "\n",
    "The k-means algorithm uses continuous-valued numeric features (k-means  can also be modified to work with categorical and ordinal features).\n",
    "\n",
    "-----\n",
    "\n",
    "Let's pick a couple of interesting continuous numeric features for analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are Funded Amount and Days to Fund related?\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the relevant columns\n",
    "relavant_colums = ['funded_amount', \n",
    "                   'days_to_fund']\n",
    "df = df[relavant_colums] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.funded_amount.hist(grid=False);\n",
    "\n",
    "ax.set(xlabel='Funded Amount', \n",
    "       ylabel='Count', \n",
    "       title='Histogram of Funded Amount');  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How can we interpret the number of loans at different funding amounts?_\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.days_to_fund.hist(grid=False);\n",
    "\n",
    "ax.set(xlabel='Days to Fund', \n",
    "       ylabel='Count', \n",
    "       title='Histogram of Days to Fund');  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How can we interpret the number of loans for different amount of times?_\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to remove outliers\n",
    "funded_small = df.funded_amount < 2_500 # Remove large loans\n",
    "time_valid = df.days_to_fund > 0 # Remove invalid times\n",
    "df = df[funded_small & time_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.funded_amount.hist(grid=False);\n",
    "\n",
    "ax.set(xlabel='Funded Amount', \n",
    "       ylabel='Count', \n",
    "       title='Histogram of Funded Amount');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.days_to_fund.hist(grid=False);df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.days_to_fund.hist(grid=False);\n",
    "\n",
    "ax.set(xlabel='Days to Fund', \n",
    "       ylabel='Count', \n",
    "       title='Histogram of Days to Fund');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[1]:,} columns in the dataframe.\")\n",
    "print(f\"There are {df.shape[0]:,} rows in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relationship between these two variables\n",
    "df.plot.scatter(x='funded_amount',\n",
    "                y='days_to_fund');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How can we interpret the relationship between the funded amount and time to fund?_\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Fitting our data with k-means using scikit-learn\n",
    "----\n",
    "\n",
    "Now we're ready to run the k-means algorithm:\n",
    "\n",
    "Let's take quick peek at the [scikit-learn's documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take KMeans class, initialize and fit it our data\n",
    "kmeans = KMeans(n_clusters=2) # Number of clusters should be 2 or 3\n",
    "kmeans.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clusters, the best way to understand them is to visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster labels for each data point to the dataframe\n",
    "df['kmeans_labels'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot k-means\n",
    "kmeans_plot = sns.lmplot(x=\"funded_amount\", \n",
    "                       y=\"days_to_fund\", \n",
    "                       data=df, \n",
    "                       fit_reg=False,        # Do not fit a regression line to the data\n",
    "                       hue=\"kmeans_labels\",  #'hue' will color code each group\n",
    "                       legend=True);\n",
    "\n",
    "# Plot the mean of cluster #1\n",
    "kmeans_plot.ax.plot(kmeans.cluster_centers_[0][0], kmeans.cluster_centers_[0][1], color='red', marker='*');\n",
    "\n",
    "# Plot the mean of cluster #2\n",
    "kmeans_plot.ax.plot(kmeans.cluster_centers_[1][0], kmeans.cluster_centers_[1][1], color='cyan', marker='*');\n",
    "\n",
    "# # Plot the mean of cluster #3 (if present)\n",
    "# kmeans_plot.ax.plot(kmeans.cluster_centers_[2][0], kmeans.cluster_centers_[2][1], color='orange', marker='*');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Why are the means where they are?_  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the number of clusters\n",
    "-----\n",
    "\n",
    "The k-means algorithm is somewhat naive -- it clusters the data into k clusters, even if k is not the right number of clusters to use.\n",
    "\n",
    "We arbitrarily set the number of clusters to be 3. But determining the appropriate number of clusters (k) is actually one of the most challenging parts of clustering. \n",
    "\n",
    "There is no hard and fast rule for what the value of k should be because the number of clusters will depend on your data and what the goal of your analysis. The number of groups you choose to partition in your data directly influences the results you'll find. In most areas of data analysis, it's attractive to take as granular an approach as possible, but having too many clusters can be counterproductive because the grouping will not tell you much.\n",
    "\n",
    "_Is it possible to have too many clusters? Or too few clusters?_\n",
    "\n",
    "Think about these extreme examples: \n",
    "\n",
    "1. A single cluster for all your data \n",
    "2. A cluster for each data point\n",
    "\n",
    "Neither of these will tell you anything new about your data! \n",
    "\n",
    "Rather, clustering is most effective when observations in the same cluster are very similar to each other. Also, we want observations in different clusters to be as different from each other as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow method to explore number of clusters\n",
    "------\n",
    "\n",
    "The elbow method is a simple, intuitive way of exploring how changing the number of clusters impacts the \"tightness\" of the clusters. \n",
    "\n",
    "The elbow method runs k-means clustering on the same dataset for a range of values of k (say, k is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) and for each value of k, calculate the within-cluster sum-of-squares errors (SSE).\n",
    "\n",
    "SSE is the distance as-the-crow* flies between each point and closest mean, squared, and summed.\n",
    "\n",
    "SSE is a measure of internally coherent clusters are. A lower is SSE is better (an inverted score), it means the each cluster is very similar to itself. SSE is like a golf score or heart-rate, lower is better.\n",
    "\n",
    "As k increases, the improvement in SSE () will lesson. At some point this lack of improvement will be rapid, creating the \"elbow\" shape.\n",
    "\n",
    "One should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data.\n",
    "\n",
    "<sub>*The figure does not look like as-the-crow distance because each axis is on very different scales. Typically, k means data is normalized so data is on the same standard scale.</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/elbow_method.png)\n",
    "\n",
    "What the elbow method does is this:\n",
    "\n",
    "1. Run the k-means algorithm over your dataset for a range of k.\n",
    "2. For each value of k, calculate how the model fits.\n",
    "3. If we see an \"elbow\" in our plotted check, then that marks a good value for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit a different model for each value of k\n",
    "k_values = range(1, 10)\n",
    "k_mean_models = [KMeans(n_clusters=i) for i in k_values] # Fit a model for each value of k\n",
    "scores = [-k_mean_models[i].fit(df).score(df) for i, model in enumerate(k_mean_models)] # See how the scores change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the effect k on the clustering\n",
    "ax = sns.pointplot(x=list(k_values),\n",
    "                   y=scores);\n",
    "ax.set(xlabel='k', \n",
    "       ylabel='Fit', \n",
    "       title='The Elbow Method choosing k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How can we interpret the relationship between changing k and the fit of clustering?_  \n",
    "_Can we see where the \"bend\" is that looks like an elbow in an arm?_\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- We talked about how supervised learning finds patterns in data.\n",
    "- Clustering is finding groups within a dataset.\n",
    "- K-means clustering is a popular clustering technique that iteratively finds the best groups and center/means of groups.\n",
    "- We fit k-means to data and evaluated the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps\n",
    "-----\n",
    "\n",
    "Apply the K-means clustering algorithm to a new pair of features. \n",
    "\n",
    "Then find an useful number of clusters (k)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further study\n",
    "-----\n",
    "\n",
    "If you want to understand k-means at a deeper level, start at the notebook found [here](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n",
    "\n",
    "If you are interested in a more theory behind k-means, a great resource is [here](https://www-users.cs.umn.edu/~kumar/dmbook/ch8.pdf). \n",
    "\n",
    "There are many other clustering methods. Another popular method is [hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
