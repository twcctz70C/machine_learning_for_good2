{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "=====\n",
    "\n",
    "Linear Regression attempts to predict a continuous outcome feature (**Y**) from one or more explanatory features (**X**).  \n",
    "\n",
    "$$Y = \\beta_0 + \\beta_1 X$$\n",
    "\n",
    "$\\beta_0$ is called the intercept term, and represents the expected mean value of Y when all explanatory features equal 0.  \n",
    "$\\beta_1$ is called a beta coefficient, and represents the expected change in the value of Y that results from a one unit change in X.  \n",
    "\n",
    "Below is an example of a linear regression with only one explanatory feature. The red dots indicate the actual data, and the blue line represents the predicted **Y** values based on the provided **X** values.  $\\beta_0$ appears to equals 0, and $\\beta_1$ appears to equal 2.\n",
    "<img src=\"./images/LinearRegression.png\" alt=\"Go Find Missing Image\" style=\"width: 500px;height=500\"/>\n",
    "\n",
    "In this lab, we will attempt to construct a linear regression in order to answer a question that Kiva borrowers may have: \n",
    "\n",
    "**What impacts the loan amount requested? **\n",
    "\n",
    "To ensure that our linear regressor is appropriate and interpretable, we will have to confirm the following assumptions are not violated:\n",
    "\n",
    "1. Linear relationship between x and y\n",
    "2. Normality\n",
    "3. Minimal multicollinearity (if multiple variables)\n",
    "4. No autocorrelation \n",
    "5. Homoscedasticity \n",
    "- Additional rule of thumb: at least 20 observations per independent variable in the analysis\n",
    "  \n",
    "If these assumptions are violated, then the predictive power of the linear regression is still valid but the information concerning the most important features is not. It is important to keep this in mind!\n",
    "\n",
    "\n",
    "Here's a look ahead at what we'll be doing in these series of notebooks: \n",
    "\n",
    "2.1 Load Data and Build Univariate Linear Regression        \n",
    "2.2 Check Assumptions  \n",
    "2.3 Build Multivariate Linear Regression  \n",
    "2.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import packages\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Packages for checking assumptions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Packages for checking assumptions\n",
    "from scipy import stats as stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# Set jupyter notebook preferences\n",
    "# the command below means that the output of multiple commands in a cell will be output at once.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# the command below tells jupyter to display up to 100 columns, this keeps everything visible\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = '../data/'\n",
    "filename = 'loans.csv'\n",
    "df = pd.read_csv(path+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Univariate Linear Regression\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test split\n",
    "\n",
    "Prior to building our model, we first need to split our dataset into a training set and a test set.  We will use our training set to train our regressor, and we will use our test set for model validation.\n",
    "To achieve this, we will use call sklearn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), and set the input parameter `test_size` to .2 so that 20% of the data will be assigned to the test set and 80% of the data will be assigned to the training set.\n",
    "\n",
    "**We set the test set aside and only look at this at the end to evaluate the models performance on unseen data.**\n",
    "\n",
    "We fix the random state so that each time we run the train_test_split code, we get the same distribution of data. This is important as keeping the data split constant allows us to compare results from different sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_number',\n",
       " 'loan_amount',\n",
       " 'lender_count',\n",
       " 'status',\n",
       " 'funded_date',\n",
       " 'funded_amount',\n",
       " 'repayment_term',\n",
       " 'location_country_code',\n",
       " 'sector',\n",
       " 'description',\n",
       " 'use']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Define our dependent variable\n",
    "y_column = 'loan_amount'\n",
    "y = df[y_column]\n",
    "# Define our independent variables\n",
    "x_columns = ['lender_count']\n",
    "X = df[x_columns]\n",
    "# Add an intercept term to the independent variables. This is needed in order to include the constant term from\n",
    "# linear regression equation.\n",
    "X['cnst'] = 1\n",
    "# Split our data into training and test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Linear Regression\n",
    "In order to build our linear regressor, we will use [statsmodels](http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) implementation.  The are other implementations out there; however, we will use statmodels because it creates a nice summary table for model evaluation. Let's print out the summary table to demonstrate how easy it is to train the model and see the results.\n",
    "\n",
    "For an in-depth review on all the statistics and numbers given in the summary below, check out this [awesome page!](http://connor-johnson.com/2014/02/18/linear-regression-with-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            loan_amount   R-squared:                       0.811\n",
      "Model:                            OLS   Adj. R-squared:                  0.811\n",
      "Method:                 Least Squares   F-statistic:                 2.059e+04\n",
      "Date:                Sun, 30 Sep 2018   Prob (F-statistic):               0.00\n",
      "Time:                        18:43:15   Log-Likelihood:                -40440.\n",
      "No. Observations:                4815   AIC:                         8.088e+04\n",
      "Df Residuals:                    4813   BIC:                         8.090e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "lender_count    31.2180      0.218    143.497      0.000      30.791      31.644\n",
      "cnst           385.4127     17.292     22.289      0.000     351.513     419.312\n",
      "==============================================================================\n",
      "Omnibus:                     3777.706   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            70703.467\n",
      "Skew:                           3.735   Prob(JB):                         0.00\n",
      "Kurtosis:                      20.222   Cond. No.                         88.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(endog=y_train, exog=X_train).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model interpretation\n",
    "-----\n",
    "\n",
    "This is the typical regression output. It's a lot to digest! \n",
    "\n",
    "Remember that our linear regression model can be represented as an equation, like this: \n",
    "\n",
    "    loan_amount = intercept + coef*lender_count\n",
    "\n",
    "What is the intercept value?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385.41268641839633"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params.cnst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does that intercept value tell us?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the coefficent for `lender_count`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.21797906322862"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params.lender_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does that coeffiecent value tell us?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "-----\n",
    "\n",
    "How do we know however, whether this is a significant result?\n",
    "\n",
    "We have a sufficient amount of confidence in this conclusion because the **p-value** is reported to be 0.000. In technical terms, the p-value is **the probability of getting results as extreme as the ones observed given no correlation. **\n",
    "\n",
    "In statistics, we want our results to fall within the 95% confidence interval, or the p-value to be <= 0.05. This means, \"[i]f repeated samples were taken and the 95% confidence interval was computed for each sample, 95% of the intervals would contain the population mean. A 95% confidence interval has a 0.95 probability of containing the population mean. 95% of the population distribution is contained in the confidence interval.\" [Read more here.](http://www.investopedia.com/terms/s/standard-error.asp) The p-value is an indicator of where we fall in the confidence interval. In English, small p-value (<= 0.05) indicates strong evidence that the coefficient is different than 0. \n",
    "\n",
    "This is a relatively simplified explanation of p-values. Don't worry if it's not immediately intuitive - [not even professional statisticians can easily explain this concept.](http://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/) To get a deeper understanding, we recommend grabbing the nearest textbook on statistics to review! \n",
    "\n",
    "Note also that the Adjusted R Squared is extremely low. To recap lessons from Module 2, the Adjusted R Squared is an explanation of how much of the outcome feature can be explained by the model's explanatory features. This low Adj R Squared suggests that the predictive value of borrower_count alone is pretty low - it cannot be used as the single feature to predict loan_amount. \n",
    "\n",
    "This result is in line with our understanding of the world - there must be other factors influencing loan_amount!\n",
    "\n",
    "**Before we start looking for other explanatory features, it is important to note that interpretation of the results above is only valid if the assumptions of linear regression are not violated. Lets go through these assumptions now...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
