{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6: Text Analysis and Natural Language Processing \n",
    "\n",
    "In this lab, we explore the text data provided by Kiva's API. Our primary source of textual data is the descriptive texts that borrowers submit for a loan request and are posted publicly on the Kiva website. Kiva is unique in that often, borrowers do not write descriptive requests for themselves, but fill out a questionnaire to Kiva's team of volunteer translators. We try to leverage this body of text (also called a *\"corpus\"*) to see if we can see any patterns in how descriptions are written.\n",
    "\n",
    "As always, we first import our packages and read in our data below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP-specific packages: \n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import names\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.text import Text  \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# output of multiple commands in a cell will be output at once.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# display up to 80 columns, this keeps everything visible\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = '~/intro_to_machine_learning/data'\n",
    "datapath = '~/Desktop'\n",
    "df = pd.read_csv(datapath+'/df.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Feature Engineering\n",
    "\n",
    "We have very limited information about translators. In fact, the only variable in our dataset relevant to translators is their name! What information can we extract from this field? \n",
    "\n",
    "In text analysis, a common yet simple task is how to categorize names by gender. We know, just in our daily knoweldge of English names, that names that end in -a are likely to be female, and names that end in -o are likely to be male (for example, Jenna and Pablo). Since we have both the gender data and the name data for the borrowers, let's use borrowers' data to train a classifier model that can predict the gender from a name! Then, we will apply this model to the translators names to predict their genders. \n",
    "\n",
    "Here, we use the Naive Bayes Classifier (for a comprehensive review, take a look back at Module 6.) This algorithm assigns a label (in our case, \"male\" or \"female\") using the last letter of the name provided in the data. Remember that we first need to clean our data to ensure that we are capturing the last letter of first names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naomi</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florence</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lucy</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kadzo</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maureen</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  gender\n",
       "0     Naomi  Female\n",
       "1  Florence  Female\n",
       "2      Lucy  Female\n",
       "3     Kadzo  Female\n",
       "4   Maureen  Female"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100961"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create name and gender dataframe for single borrowers\n",
    "kiva_names = df[['name', 'gender', 'borrower_count']]\n",
    "kiva_names = kiva_names[['name', 'gender']][kiva_names['borrower_count'] == 1]\n",
    "\n",
    "kiva_names.head(5)\n",
    "len(kiva_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from looking through the data that there are some instances in which the name is not an individual's first name, but rather the name of a business or a collective, or \"Anonymous\". Let's drop these out of our training dataset as they won't be helpful in determining the gender of a person. Let's also select only the first name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12761"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0         Naomi\n",
       "1      Florence\n",
       "2          Lucy\n",
       "3         Kadzo\n",
       "4       Maureen\n",
       "5         Grace\n",
       "6        Martha\n",
       "7        Zawadi\n",
       "8         Susan\n",
       "9     Christine\n",
       "10        Lydia\n",
       "11         Jane\n",
       "12         Mary\n",
       "13      Richard\n",
       "14    Valentine\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm null values, anonymous, and duplicates\n",
    "\n",
    "kiva_names = kiva_names.loc[kiva_names['name'].isnull() == False]\n",
    "kiva_names = kiva_names.drop_duplicates()\n",
    "kiva_names = kiva_names[kiva_names['name'] != \"Anonymous\"]\n",
    "kiva_names['name'] = kiva_names['name'].str.split(expand=True)[0]\n",
    "\n",
    "len(kiva_names['name'])\n",
    "kiva_names['name'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that will return the last letter of our borrowers' first names. This letter will be a **feature** we will use to attempt to predict the output feature, gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function that returns last letter of first name \n",
    "def gender_features(name):\n",
    "    return {'last_letter': name[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prepare to train our model. We split train and test sets as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10208"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2552"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set training-test split %\n",
    "split_pct = 0.80\n",
    "\n",
    "# Remove null and NaN values \n",
    "kiva_names = kiva_names[pd.notnull(kiva_names)]\n",
    "\n",
    "# the pandas command \"sample\" already randomizes its selection. \n",
    "kiva_names_shuffled = kiva_names.sample(frac=1)\n",
    "\n",
    "kiva_train_set = kiva_names_shuffled[:int((len(kiva_names_shuffled)*split_pct))] \n",
    "kiva_test_set = kiva_names_shuffled[int(len(kiva_names_shuffled)*split_pct+1):]  \n",
    "\n",
    "len(kiva_train_set.index)\n",
    "len(kiva_test_set.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare our data by converting the name and gender features from features into lists, so they are associated with each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva_female_train = kiva_train_set[kiva_train_set['gender'] == \"Female\"]\n",
    "kiva_male_train = kiva_train_set[kiva_train_set['gender'] == \"Male\"]\n",
    "kiva_female_test = kiva_test_set[kiva_test_set['gender'] == \"Female\"]\n",
    "kiva_male_test = kiva_test_set[kiva_test_set['gender'] == \"Male\"]\n",
    "\n",
    "kiva_train_feature_set = [(name, \"female\") for name in kiva_female_train['name']] + \\\n",
    "[(name, \"male\") for name in kiva_male_train['name']]\n",
    "\n",
    "kiva_test_feature_set = [(name, \"female\") for name in kiva_female_test['name']] + \\\n",
    "[(name, \"male\") for name in kiva_male_test['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva_train_feature_set = [(gender_features(n), g) for (n, g) in kiva_train_feature_set]\n",
    "kiva_test_feature_set = [(gender_features(n), g) for (n, g) in kiva_test_feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kiva_classifier = nltk.NaiveBayesClassifier.train(kiva_train_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's test out our new classifier! \n",
    "\n",
    "kiva_classifier.classify(gender_features('Cleopatra'))\n",
    "kiva_classifier.classify(gender_features('Maximillian'))\n",
    "kiva_classifier.classify(gender_features('James'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it works okay for our three samples, but let's get a better sense of overall accuracy.\n",
    "\n",
    "The nltk \"accuracy()\" method returns the % of time our predictions are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'k'              male : female =     18.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.1 : 1.0\n",
      "             last_letter = 'f'              male : female =     10.3 : 1.0\n",
      "             last_letter = 'w'              male : female =      6.1 : 1.0\n",
      "             last_letter = 'd'              male : female =      5.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Find out which features were most informative in determining outcome\n",
    "\n",
    "kiva_classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show most informative features: this returns LIKELIHOOD RATIOS. For the first entry \"f\", we see that males are more likely to have this letter as their last letter by the factor indicated above.\n",
    "\n",
    "But how accurate is this? Let's run this classifier on our test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7021943573667712\n"
     ]
    }
   ],
   "source": [
    "#Get a sense of overall accuracy\n",
    "\n",
    "print(nltk.classify.accuracy(kiva_classifier, kiva_test_feature_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction is okay, but not amazing. Remember that a random generator of genders would likely get an accuracy of about 50%, so at least we are better than random. One potential hypothesis for why we are not better at classifying genders might be because this particular dataset mixes Kenyan and American first names. Whereas you might expect an American female name to end in -a and an American male name to end in -o (e.g. Jenna and Julio), these conventions do not necessarily hold for Kenyan names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our model to try and predict our translators' names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translator_first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Madhurima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Teresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   translator_first_name\n",
       "0               Michelle\n",
       "8                    Tim\n",
       "9              Madhurima\n",
       "20                Teresa\n",
       "23                  John"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translators = pd.DataFrame()\n",
    "translators['translator_first_name'] = df['translator.byline'].str.split(expand=True)[0]\n",
    "\n",
    "# rm null values and duplicates\n",
    "translators = translators.loc[translators['translator_first_name'].isnull() == False]\n",
    "translators = translators.drop_duplicates()\n",
    "\n",
    "translators.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'last_letter': 'e'}\n",
       "8     {'last_letter': 'm'}\n",
       "9     {'last_letter': 'a'}\n",
       "20    {'last_letter': 'a'}\n",
       "23    {'last_letter': 'n'}\n",
       "Name: last_letter, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translators['last_letter'] = translators['translator_first_name'].apply(lambda x: gender_features(x))\n",
    "translators_last = translators['last_letter']\n",
    "translators_last[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translator_first_name</th>\n",
       "      <th>last_letter</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelle</td>\n",
       "      <td>{'last_letter': 'e'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tim</td>\n",
       "      <td>{'last_letter': 'm'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Madhurima</td>\n",
       "      <td>{'last_letter': 'a'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Teresa</td>\n",
       "      <td>{'last_letter': 'a'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>John</td>\n",
       "      <td>{'last_letter': 'n'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sheilah</td>\n",
       "      <td>{'last_letter': 'h'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Patrick</td>\n",
       "      <td>{'last_letter': 'k'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lynn</td>\n",
       "      <td>{'last_letter': 'n'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Frederick</td>\n",
       "      <td>{'last_letter': 'k'}</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mike</td>\n",
       "      <td>{'last_letter': 'e'}</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   translator_first_name           last_letter  gender\n",
       "0               Michelle  {'last_letter': 'e'}  female\n",
       "8                    Tim  {'last_letter': 'm'}    male\n",
       "9              Madhurima  {'last_letter': 'a'}  female\n",
       "20                Teresa  {'last_letter': 'a'}  female\n",
       "23                  John  {'last_letter': 'n'}    male\n",
       "24               Sheilah  {'last_letter': 'h'}  female\n",
       "26               Patrick  {'last_letter': 'k'}    male\n",
       "27                  Lynn  {'last_letter': 'n'}    male\n",
       "29             Frederick  {'last_letter': 'k'}    male\n",
       "30                  Mike  {'last_letter': 'e'}  female"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translators['gender'] = translators_last.apply(lambda x: kiva_classifier.classify(x))\n",
    "translators.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - even in this small sample of 10, we see that the accuracy rate is far from perfect. Using our own understanding of what gender we would assign the names we see, this sample has an accuracy score of 60%. Not great.  \n",
    "\n",
    "**How can we make this prediction better? Can you think of other aspects of a name might be predictive of gender?** \n",
    "A quick test we can try is using the final two letters of a name instead of just one. Try it! \n",
    "\n",
    "We just completed our first supervised learning exercise: classification. Let's move forward in our question to finding patterns in the descriptions of the loans by translators, our unsupervised learning exercise. First we need to clean the text data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text \n",
    "\n",
    "Cleaning text is almost always required in text analysis. You have already gotten a taste of this in this notebook when you cleaned the variable \"name\" to exclude business names, and in past notebooks as well. \n",
    "\n",
    "Cleaning can be as extensive as you want it to be, depending on what serves your research question the best. Is it best to look at full sentences, so you can retain the context of words? Is it best to look at individual words? Should you remove grammar, HTML code, stopwords? \n",
    "\n",
    "Before answering this question, we have to know what's in our data. Let's turn to some exploratory analyses to determine how we should clean our data.\n",
    "\n",
    "Note that we don't run the following snippets of code on the whole dataset as text analysis is very computationally expensive and may crash your computer. Instead, we draw a sample of 1000 descriptions from the dataset. *This means that your results will look slightly different, but that's okay -- make sure to post on Slack anything you find interesting!*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Luvuno is from Samburu and has a fruits and vegetables business. She sells from her home and also around Samburu.\\r\\r\\r\\r\\r\\n\\r\\r\\r\\r\\r\\nLuvuno says that she has been able to help her family through her business and that she has given them all that they need to continue having a dignified life, with no deprivations. \\r\\r\\r\\r\\r\\n\\r\\r\\r\\r\\r\\nLuvuno wants to be able to continue working and helping her family, so she is asking for this loan to invest in fruits and vegetables, to continue working and offering good products to her customers.\\r\\r\\r\\r\\r\\n', 'Paul is a nurse/midwife managing his own private facility in Vihiga in the western part of Kenya.  He is 40 years old and lives with his wife and two children in Kakamega. His wife who is also a trained nurse and works at Kakamega Provincial General Hospital. <p>Paul trained as a nurse/midwife in 1990 and has since operated his own private clinic at Stend Kisa in Vihiga. He offers a wide range of clinical services including general curative, family planning, maternal and child health services, and also runs a pharmacy and a laboratory. Paul attributes his success to hard work, perseverance and the good reputation he has built with the locals. He requires US $1200 to enable him to purchase an additional stock of drugs and to integrate other services.', 'Mary is 43-years-old, married and has three children.  She runs a retail shop so as to earn a living.  She has operated the business for four years.  She has retained the business because of her good customer care. She also does livestock farming to supplement her income.  She is grateful to Faulu Kenya because she has been able to access business loans.\\r\\r\\r\\r\\r\\n\\r\\r\\r\\r\\r\\nMary hopes to expand her business into a wholesale operation in the future.  She has requested 50,000 Kenya shillings to buy a cow.\\r\\r\\r\\r\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "def text_to_list(df, text_field, sample_num = 1000):\n",
    "    \"\"\"Convert a text field in the dataframe to a (sampled) list of strings.\"\"\"\n",
    "    # read all non-null text into a single df\n",
    "    text_raw = df[text_field][df[text_field].isnull() == False]\n",
    "\n",
    "    # take sample of n (default 1000) entries, read into list\n",
    "    # set random_state parameter to draw the same sample\n",
    "    text_raw_abridged = text_raw.sample(sample_num) \n",
    "    text = list(map(str, text_raw_abridged))\n",
    "    return(text)\n",
    "\n",
    "text = text_to_list(df, 'description.texts.en')\n",
    "\n",
    "print(text[0:3]) # Each sentence is an item in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is some HTML/CSS cluttering up the text. Below, we remove these and convert all capital letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['luvuno is from samburu and has a fruits and vegetables business she sells from her home and also around samburu luvuno says that she has been able to help her family through her business and that she has given them all that they need to continue having a dignified life with no deprivations luvuno wants to be able to continue working and helping her family so she is asking for this loan to invest in fruits and vegetables to continue working and offering good products to her customers', 'paul is a nurse/midwife managing his own private facility in vihiga in the western part of kenya he is 40 years old and lives with his wife and two children in kakamega his wife who is also a trained nurse and works at kakamega provincial general hospital paul trained as a nurse/midwife in 1990 and has since operated his own private clinic at stend kisa in vihiga he offers a wide range of clinical services including general curative family planning maternal and child health services and also runs a pharmacy and a laboratory paul attributes his success to hard work perseverance and the good reputation he has built with the locals he requires us $1200 to enable him to purchase an additional stock of drugs and to integrate other services', 'mary is 43-years-old married and has three children she runs a retail shop so as to earn a living she has operated the business for four years she has retained the business because of her good customer care she also does livestock farming to supplement her income she is grateful to faulu kenya because she has been able to access business loans mary hopes to expand her business into a wholesale operation in the future she has requested 50 000 kenya shillings to buy a cow']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Remove tags and punctuation and convert to lowercase.\"\"\"\n",
    "    # Remove HTML \n",
    "    text = [w.replace('\\r', ' ') for w in text]\n",
    "    text = [w.replace('\\n', ' ') for w in text]\n",
    "    text = [w.replace('<br />', ' ') for w in text]\n",
    "    text = [w.replace('<p>', ' ') for w in text]\n",
    "    text = [w.replace('</p>', ' ') for w in text]\n",
    "    text = [w.replace('<i>', ' ') for w in text]\n",
    "    text = [w.replace('</i>', ' ') for w in text]\n",
    "    text = [w.replace('.', ' ') for w in text]\n",
    "    text = [w.replace(',', ' ') for w in text]\n",
    "    text = [w.replace('?', '') for w in text]\n",
    "    text = [w.replace(';', '') for w in text]\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = [\" \".join(t.split()) for t in text]\n",
    "\n",
    "    # Lowercase\n",
    "    text = [w.lower() for w in text]\n",
    "    \n",
    "    return(text)\n",
    "\n",
    "text = clean_text(text)\n",
    "\n",
    "print(text[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to buy mobile phone accessories', 'to buy a dairy cow', 'to buy cattle feed and a goat']\n"
     ]
    }
   ],
   "source": [
    "# Use the same text cleaning functions for the use text field\n",
    "use_text = text_to_list(df, 'use')\n",
    "use_text = clean_text(use_text)\n",
    "\n",
    "print(use_text[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The text looks clean. We also notice that this dataset is a list where every item in the list is a description. Now we tokenize each item in the list so that each word is separated out. This yields a list of lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['luvuno',\n",
       "  'is',\n",
       "  'from',\n",
       "  'samburu',\n",
       "  'and',\n",
       "  'has',\n",
       "  'a',\n",
       "  'fruits',\n",
       "  'and',\n",
       "  'vegetables',\n",
       "  'business',\n",
       "  'she',\n",
       "  'sells',\n",
       "  'from',\n",
       "  'her',\n",
       "  'home',\n",
       "  'and',\n",
       "  'also',\n",
       "  'around',\n",
       "  'samburu',\n",
       "  'luvuno',\n",
       "  'says',\n",
       "  'that',\n",
       "  'she',\n",
       "  'has',\n",
       "  'been',\n",
       "  'able',\n",
       "  'to',\n",
       "  'help',\n",
       "  'her',\n",
       "  'family',\n",
       "  'through',\n",
       "  'her',\n",
       "  'business',\n",
       "  'and',\n",
       "  'that',\n",
       "  'she',\n",
       "  'has',\n",
       "  'given',\n",
       "  'them',\n",
       "  'all',\n",
       "  'that',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'having',\n",
       "  'a',\n",
       "  'dignified',\n",
       "  'life',\n",
       "  'with',\n",
       "  'no',\n",
       "  'deprivations',\n",
       "  'luvuno',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'working',\n",
       "  'and',\n",
       "  'helping',\n",
       "  'her',\n",
       "  'family',\n",
       "  'so',\n",
       "  'she',\n",
       "  'is',\n",
       "  'asking',\n",
       "  'for',\n",
       "  'this',\n",
       "  'loan',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'in',\n",
       "  'fruits',\n",
       "  'and',\n",
       "  'vegetables',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'working',\n",
       "  'and',\n",
       "  'offering',\n",
       "  'good',\n",
       "  'products',\n",
       "  'to',\n",
       "  'her',\n",
       "  'customers'],\n",
       " ['paul',\n",
       "  'is',\n",
       "  'a',\n",
       "  'nurse/midwife',\n",
       "  'managing',\n",
       "  'his',\n",
       "  'own',\n",
       "  'private',\n",
       "  'facility',\n",
       "  'in',\n",
       "  'vihiga',\n",
       "  'in',\n",
       "  'the',\n",
       "  'western',\n",
       "  'part',\n",
       "  'of',\n",
       "  'kenya',\n",
       "  'he',\n",
       "  'is',\n",
       "  '40',\n",
       "  'years',\n",
       "  'old',\n",
       "  'and',\n",
       "  'lives',\n",
       "  'with',\n",
       "  'his',\n",
       "  'wife',\n",
       "  'and',\n",
       "  'two',\n",
       "  'children',\n",
       "  'in',\n",
       "  'kakamega',\n",
       "  'his',\n",
       "  'wife',\n",
       "  'who',\n",
       "  'is',\n",
       "  'also',\n",
       "  'a',\n",
       "  'trained',\n",
       "  'nurse',\n",
       "  'and',\n",
       "  'works',\n",
       "  'at',\n",
       "  'kakamega',\n",
       "  'provincial',\n",
       "  'general',\n",
       "  'hospital',\n",
       "  'paul',\n",
       "  'trained',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nurse/midwife',\n",
       "  'in',\n",
       "  '1990',\n",
       "  'and',\n",
       "  'has',\n",
       "  'since',\n",
       "  'operated',\n",
       "  'his',\n",
       "  'own',\n",
       "  'private',\n",
       "  'clinic',\n",
       "  'at',\n",
       "  'stend',\n",
       "  'kisa',\n",
       "  'in',\n",
       "  'vihiga',\n",
       "  'he',\n",
       "  'offers',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'of',\n",
       "  'clinical',\n",
       "  'services',\n",
       "  'including',\n",
       "  'general',\n",
       "  'curative',\n",
       "  'family',\n",
       "  'planning',\n",
       "  'maternal',\n",
       "  'and',\n",
       "  'child',\n",
       "  'health',\n",
       "  'services',\n",
       "  'and',\n",
       "  'also',\n",
       "  'runs',\n",
       "  'a',\n",
       "  'pharmacy',\n",
       "  'and',\n",
       "  'a',\n",
       "  'laboratory',\n",
       "  'paul',\n",
       "  'attributes',\n",
       "  'his',\n",
       "  'success',\n",
       "  'to',\n",
       "  'hard',\n",
       "  'work',\n",
       "  'perseverance',\n",
       "  'and',\n",
       "  'the',\n",
       "  'good',\n",
       "  'reputation',\n",
       "  'he',\n",
       "  'has',\n",
       "  'built',\n",
       "  'with',\n",
       "  'the',\n",
       "  'locals',\n",
       "  'he',\n",
       "  'requires',\n",
       "  'us',\n",
       "  '$',\n",
       "  '1200',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'him',\n",
       "  'to',\n",
       "  'purchase',\n",
       "  'an',\n",
       "  'additional',\n",
       "  'stock',\n",
       "  'of',\n",
       "  'drugs',\n",
       "  'and',\n",
       "  'to',\n",
       "  'integrate',\n",
       "  'other',\n",
       "  'services']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(map(word_tokenize, text))\n",
    "kiva_text = nltk.Text(tokens)\n",
    "kiva_text[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams and word prediction\n",
    "\n",
    "The task of predicting the next word in a sentence might seem irrelevant if one thinks of natural language processing (NLP) only in terms of processing text for semantic understanding. However, NLP also involves processing noisy data and checking text for errors. For example, noisy data can be produced in speech or handwriting recognition, as the computer may not properly recognize words due to unclear speech or handwriting that differs significantly from the computer’s model. Additionally, NLP could be extended to such functions as spell checking in order to catch errors in which no word is misspelled but the user has accidentally typed a word that she or he did not intend. In the sentence “I picked up the phone to answer her fall,” for instance, fall may have been the intended word, but it is more likely that call was simply mistyped. A spell checker cannot catch this error because both fall and call are English words. An NLP algorithm that could catch this error would thus need to look beyond what letters form words and instead attempt to determine what word is most probable in a given sentence.\n",
    "\n",
    "### N-Gram Models\n",
    "One of the oldest methods used in trying to compute the probability that a given word is the next word in a sentence is employing n-gram models. N-gram models are attempts to guess the next word in a sentence based upon the (n - 1) previous words in the sentence. These models base their guesses on the probability of a given word without any context (i.e., the is a more common word than green and is thus more probable than green if context is ignored) and the probability of a word given the last (n – 1) words. For example, take the sentence beginning “The four leaf clover was the color...”. Using a bigram model, one would compute P(green | color) and P(the | color) to determine the more probable guess between these two words. Based on this example, one might imagine that the model’s guess would be even more accurate if we computed P(green | The four leaf clover was the color), making a 7-gram model. However, such a model would take enormous computing power and a much greater amount of time than the bigram model to compute. Since good estimates can be made based on smaller models, it is more practical to use bi- or trigram models. This idea that a future event (in this case, the next word) can be predicted using a relatively short history (for the example, one or two words) is called a Markov assumption.\n",
    "\n",
    "In order to make these predictions about the next word in a sentence, the NLP application must have access to probabilities about how often specific words occur in general and how often specific words occur after particular words. To program a computer with these probabilities by hand would be extremely tedious and raises the question of how those probabilities would be reached in the first place. A simple way to find the probabilities might involve counting the number of occurrences of words in samples of text; however, a human would probably become introduce errors into this process and be unable to sort through millions of words quickly. Thus, n-gram models are usually trained on corpora, huge text files that can be processed to determine statistical properties about the words and sentences within.\n",
    "\n",
    "Source: https://cs.stanford.edu/people/eroberts/courses/soco/projects/2004-05/nlp/techniques_word.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Here we create and implement a trigram model. \n",
    "\n",
    "First, we convert the text list to a dictionary mapping the first two words to a third word that follows. We save this dictionary as the object `chains`.\n",
    "\n",
    "Next, we use these chains to make a text string. Using a random starting bigram, we add a word by selecting one word among the possible words that can follow. \n",
    "\n",
    "Then we repeat this word selection process for the next pair of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "def make_chains(text_list):\n",
    "    \"\"\"Takes input text as string; returns _dictionary_ of markov chains.\n",
    "\n",
    "    A chain will be a key that consists of a tuple of (word1, word2)\n",
    "    and the value would be a list of the word(s) that follow those two\n",
    "    words in the input text.\n",
    "\n",
    "    For example:\n",
    "\n",
    "        >>> make_chains(\"hi there mary hi there juanita\")\n",
    "        {('hi', 'there'): ['mary', 'juanita'], ('there', 'mary'): ['hi'], ('mary', 'hi': ['there']}\n",
    "    \"\"\"\n",
    "    \n",
    "    word_list = []\n",
    "    for sentences in text_list:\n",
    "        words = sentences.split(' ')\n",
    "        for word in words:\n",
    "            word_list.append(word)\n",
    "\n",
    "    ## Let's make trigrams\n",
    "    chains = {}\n",
    "    # word_three_list = []\n",
    "    for i in range((len(word_list)-2)):\n",
    "        key = (word_list[i], word_list[i+1])\n",
    "        word_three = word_list[i+2]  \n",
    "\n",
    "        if key not in chains:        \n",
    "            chains[key] = [word_three]            \n",
    "\n",
    "        else:       \n",
    "            chains[key].append(word_three)\n",
    "\n",
    "    return chains\n",
    "\n",
    "def make_text(chains, text_len, silent_start = False):\n",
    "    \"\"\"Takes dictionary of markov chains; returns random text.\"\"\"\n",
    "\n",
    "    text = \"\"\n",
    "    fake_text = []\n",
    "    starting_tuple = choice(list(chains.keys()))\n",
    "    fake_text.append(starting_tuple)\n",
    "    \n",
    "    if not silent_start:\n",
    "        print('Starting bigram: ' + ' '.join(starting_tuple))\n",
    "\n",
    "    for i in range(text_len):\n",
    "        add_text(fake_text, chains)\n",
    "    \n",
    "    result_text = ' '.join([i for tup in fake_text for i in tup])\n",
    "        \n",
    "    return(result_text)\n",
    "\n",
    "def add_text(fake_text, chains):\n",
    "    \"\"\"Helper function to add a randomly selected third word based on a starting bigram.\"\"\"\n",
    "    starting_tuple = fake_text[-1]\n",
    "    for key in chains.keys():\n",
    "        random_word = choice(list(chains[starting_tuple]))\n",
    "        \n",
    "        if random_word == key[0]:\n",
    "            fake_text.append(key)\n",
    "            break\n",
    "            \n",
    "    return(fake_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting words\n",
    "\n",
    "Let's try our prediction functions on our cleaned text fields! Please share any funny ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting bigram: competition and\n",
      "competition and lack of water that is from a nurse/midwife in fruits and has a trained nurse and works at kakamega his\n"
     ]
    }
   ],
   "source": [
    "# Get a Markov chain for the description text field\n",
    "chains = make_chains(text)\n",
    "\n",
    "# Produce random text\n",
    "random_text = make_text(chains, 10)\n",
    "\n",
    "print(random_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting bigram: cabbages kales\n",
      "cabbages kales and a goat to buy cattle feed for her cafe\n"
     ]
    }
   ],
   "source": [
    "# Get a Markov chain for the use text field\n",
    "chains = make_chains(use_text)\n",
    "\n",
    "# Produce random text\n",
    "random_text = make_text(chains, 5)\n",
    "\n",
    "print(random_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary investigations / visualizations \n",
    "\n",
    "Now that we've got cleaned data, let's conduct some preliminary investigations. Frequency, concordance and similar are all functions of the NLTK package that can give us a sense of what is in our text without our having to read every single line.\n",
    "\n",
    "- Frequency\n",
    "- Concordance\n",
    "- Similar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency returns a list of unique words, with how often each word shows up in the corpus. This provides an idea of what words are included in the descriptions of loan requests in Kenya. Note that the most common words are relatively uninformative, such as \"to,\" \"and,\" or \"is.\" Later we will remove these for analysis so they do not overinfluence our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all sentences into single list \n",
    "\n",
    "text_corpus = list() \n",
    "\n",
    "for x in range(0, len(kiva_text)): \n",
    "    text_corpus.extend(kiva_text[x])\n",
    "\n",
    "text_corpus = nltk.Text(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5397),\n",
       " ('and', 4336),\n",
       " ('a', 3883),\n",
       " ('the', 3861),\n",
       " ('she', 3561),\n",
       " ('is', 3226),\n",
       " ('her', 3107),\n",
       " ('of', 2796),\n",
       " ('in', 2274),\n",
       " ('for', 1974),\n",
       " ('has', 1916),\n",
       " ('business', 1866),\n",
       " ('he', 1789),\n",
       " ('loan', 1601),\n",
       " ('his', 1496),\n",
       " ('will', 1411),\n",
       " ('with', 1264),\n",
       " ('years', 1239),\n",
       " ('this', 1107),\n",
       " ('children', 1010),\n",
       " ('from', 874),\n",
       " ('that', 828),\n",
       " ('be', 784),\n",
       " ('been', 767),\n",
       " ('as', 630)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kiva_fdist.plot()\n",
    "#kiva_fdist.plot(50, cumulative=True)\n",
    "kiva_fdist = nltk.FreqDist(text_corpus)\n",
    "kiva_fdist.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concordance takes an input word of your choosing and returns the surrounding words. This provides important context about how a specific word is used in the text corpus. Here, we test \"future\", \"seasonality\", and \"working\". Note that sme of these words are used differently or ambiguously. This gets at an important point for NLP - words can be and are used ambiguously and it is difficult to parse meaning unless we also take a look at context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 99 matches:\n",
      "nd make a loan ! johnson is a married man he describes himself to be focused he\n",
      "arming david is a 31-year-old married man with three children he has been runni\n",
      " hire richard is a 26-year-old single man who has had to overcome a lot of adve\n",
      "way of life he is a very enterprising man and although he never had a formal ed\n",
      " and happy family davies is a married man he has five children he operates a ta\n",
      "repaid successfully joab is a married man he has 3 children he describes himsel\n",
      "lets jackson is a 29-year-old married man who has been blessed with three child\n",
      "financial support joseph is a married man he has 4 children he describes himsel\n",
      "r services felix is a happily married man and is blessed with 2 children his wi\n",
      "oost his business he is a hardworking man who will use profits from his busines\n",
      "ost her business richard is a married man with five children who are in school \n",
      "stallments billy is a happily married man who lives in bomet with his family he\n",
      "cial independence he is a hardworking man who is determined to achieve his set \n",
      "s loan henry is a 58-year-old married man he has eight children with ages rangi\n",
      " and loan now wilson is a 58-year-old man from migori western kenya and is marr\n",
      " stable john is a 32-year-old married man with two children he runs an electron\n",
      "to her customers michael is a married man he has 5 children he describes himsel\n",
      "s jonathan w is a 35-year-old married man with three children living with him i\n",
      "microfinance bank hudson is a married man with nine children all in primary sch\n",
      "eeds muchiri is a 45-year-old married man he has two children ages 2 and 16 he \n",
      " describes himself to be a consistent man he operates a retail store where he s\n",
      "educate her children john kiptoo is a man of thirty five years who is married w\n",
      "le of his family ibrahim is a married man with seven children he describes hims\n",
      "ble cleophas is a 32-year-old married man with four children he describes himse\n",
      "es in farming nathan is a 34-year-old man from kakamega which is located in the\n"
     ]
    }
   ],
   "source": [
    "text_corpus.concordance('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 225 matches:\n",
      "l of 8 25 acres `` esha is a married woman with five children all of whom atten\n",
      "rything they need loice is a married woman with four children all of whom gradu\n",
      "oost her business monica is a single woman who has 2 children she operates a fa\n",
      " 10 solar lights biliah is a married woman she has three children she describes\n",
      "boost her business saumu is a single woman with one child who attends school sh\n",
      "loring materials bendera is a single woman with three children all of whom atte\n",
      "t her business everlyne is a married woman she has three children with ages ran\n",
      "ap for resale elizabeth is a married woman she has two children she describes h\n",
      " of 4 75 acres magdaline is a single woman and has one child she describes hers\n",
      "e has experienced susan is a married woman she has 2 children she describes her\n",
      "rds of his family ritah is a married woman she has one child she describes hers\n",
      "in a biodigester fahima is a married woman with two children all of whom attend\n",
      "d fertilizers jenerusha is a married woman she has four children she describes \n",
      "essfully repaid jemimah is a married woman with three children all of whom atte\n",
      "gion lilian is a 36-year-old married woman she has 3 children with ages ranging\n",
      " buy a home mwanamwisho is a married woman with three children she lives in a r\n",
      "cially stable mwanamkuu is a married woman with two school-going children she o\n",
      "and husband please support a working woman with a loan ! okumus group has 7 gro\n",
      "is 53 years old she is a hardworking woman who is married to abdalla and togeth\n",
      "with her family mariamu is a married woman with three children two of whom atte\n",
      "her previous one fatuma is a married woman with four children three of whom sti\n",
      "mily pamela is a 42-year-old married woman she has 4 children she describes her\n",
      "iving standards mwanasha is a single woman with three children all of whom atte\n",
      "tals beatrice is a charismatic young woman and a strong example of hard work be\n",
      " : www kadet co ke arafa is a single woman who for the last 16 years has been s\n"
     ]
    }
   ],
   "source": [
    "text_corpus.concordance('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar takes in an input word of your choosing, but returns other words that appear in a similar range of contexts. This is called finding the \"distributional similarity.\" Most similar words appear first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan farmer father woman business profit group businessman family shop\n",
      "living cow challenge farm man house community lack supplier plot\n"
     ]
    }
   ],
   "source": [
    "text_corpus.similar(\"mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother loan farmer business part stock challenge farm man area lack\n",
      "person variety city dream lady shortage piece help family\n"
     ]
    }
   ],
   "source": [
    "text_corpus.similar(\"father\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations are pairs of words that occur together in the data unusually often. Here, we recognize pairs of words that are familiar to us in day-to-day life and indicate a writing style, such as \"major challenge\" or \"primary customers\". There are also unexpected pairings, like \"three children.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years old; acre fund; one acre; juhudi kilimo; school fees; piped\n",
      "water; 000 kes; kadet ltd; primary customers; join yehu; married\n",
      "woman; greatest monthly; first loan; microfinance bank; five years;\n",
      "anticipated profits; major challenge; three children; smep\n",
      "microfinance; wheat flour\n"
     ]
    }
   ],
   "source": [
    "text_corpus.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words\n",
    "\n",
    "\"Stop words\" are words like \"to\", \"the\", \"a\" - words that are plentiful but do not offer significantly meaningful information about the document. Here, we import a predetermined set of stop words defined by the NLTK package and then remove them from the dataset. The resulting dataset has words that we can generally agree are meaningful and say something about the content of the loan request. You can also define your own set of \"stop words\" to remove if you have a very specific set of words you want to remove. \n",
    "\n",
    "However, we see that these words still have suffixes such as \"-s\" and \"-ing\". We want to remove these because if we do not, the algorithm will count a set of words like \"married\" and \"marries\" as different words, when we can consider them, for our purposes, the same word. To remove these, we stem our text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " 'she',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'y',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luvuno',\n",
       " 'samburu',\n",
       " 'fruits',\n",
       " 'vegetables',\n",
       " 'business',\n",
       " 'sells',\n",
       " 'home',\n",
       " 'also',\n",
       " 'around',\n",
       " 'samburu',\n",
       " 'luvuno',\n",
       " 'says',\n",
       " 'able',\n",
       " 'help',\n",
       " 'family',\n",
       " 'business',\n",
       " 'given',\n",
       " 'need',\n",
       " 'continue',\n",
       " 'dignified',\n",
       " 'life',\n",
       " 'deprivations',\n",
       " 'luvuno',\n",
       " 'wants',\n",
       " 'able',\n",
       " 'continue',\n",
       " 'working',\n",
       " 'helping',\n",
       " 'family',\n",
       " 'asking',\n",
       " 'loan',\n",
       " 'invest',\n",
       " 'fruits',\n",
       " 'vegetables',\n",
       " 'continue',\n",
       " 'working',\n",
       " 'offering',\n",
       " 'good',\n",
       " 'products',\n",
       " 'customers',\n",
       " 'paul',\n",
       " 'nurse/midwife',\n",
       " 'managing',\n",
       " 'private',\n",
       " 'facility',\n",
       " 'vihiga',\n",
       " 'western',\n",
       " 'part',\n",
       " 'kenya',\n",
       " '40']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stop words\n",
    "\n",
    "text_corpus_clean = [word for word in text_corpus if word not in stopwords.words('english')]\n",
    "text_corpus_clean[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem words \n",
    "\n",
    "The Porter Stemmer is one of several stemming tools (including Snowball Stemmer and the Lancaster Stemmer). Each type of stemmer uses different rules to \"stem\" a word like \"running\" to \"run\". Here we use the Porter Stemmer as it is very commonly used. Try others! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luvuno',\n",
       " 'samburu',\n",
       " 'fruit',\n",
       " 'veget',\n",
       " 'busi',\n",
       " 'sell',\n",
       " 'home',\n",
       " 'also',\n",
       " 'around',\n",
       " 'samburu',\n",
       " 'luvuno',\n",
       " 'say',\n",
       " 'abl',\n",
       " 'help',\n",
       " 'famili',\n",
       " 'busi',\n",
       " 'given',\n",
       " 'need',\n",
       " 'continu',\n",
       " 'dignifi',\n",
       " 'life',\n",
       " 'depriv',\n",
       " 'luvuno',\n",
       " 'want',\n",
       " 'abl',\n",
       " 'continu',\n",
       " 'work',\n",
       " 'help',\n",
       " 'famili',\n",
       " 'ask',\n",
       " 'loan',\n",
       " 'invest',\n",
       " 'fruit',\n",
       " 'veget',\n",
       " 'continu',\n",
       " 'work',\n",
       " 'offer',\n",
       " 'good',\n",
       " 'product',\n",
       " 'custom',\n",
       " 'paul',\n",
       " 'nurse/midwif',\n",
       " 'manag',\n",
       " 'privat',\n",
       " 'facil',\n",
       " 'vihiga',\n",
       " 'western',\n",
       " 'part',\n",
       " 'kenya',\n",
       " '40',\n",
       " 'year',\n",
       " 'old',\n",
       " 'live',\n",
       " 'wife',\n",
       " 'two',\n",
       " 'children',\n",
       " 'kakamega',\n",
       " 'wife',\n",
       " 'also',\n",
       " 'train',\n",
       " 'nurs',\n",
       " 'work',\n",
       " 'kakamega',\n",
       " 'provinci',\n",
       " 'gener',\n",
       " 'hospit',\n",
       " 'paul',\n",
       " 'train',\n",
       " 'nurse/midwif',\n",
       " '1990',\n",
       " 'sinc',\n",
       " 'oper',\n",
       " 'privat',\n",
       " 'clinic',\n",
       " 'stend',\n",
       " 'kisa',\n",
       " 'vihiga',\n",
       " 'offer',\n",
       " 'wide',\n",
       " 'rang',\n",
       " 'clinic',\n",
       " 'servic',\n",
       " 'includ',\n",
       " 'gener',\n",
       " 'cur',\n",
       " 'famili',\n",
       " 'plan',\n",
       " 'matern',\n",
       " 'child',\n",
       " 'health',\n",
       " 'servic',\n",
       " 'also',\n",
       " 'run',\n",
       " 'pharmaci',\n",
       " 'laboratori',\n",
       " 'paul',\n",
       " 'attribut',\n",
       " 'success',\n",
       " 'hard',\n",
       " 'work',\n",
       " 'persever',\n",
       " 'good',\n",
       " 'reput',\n",
       " 'built',\n",
       " 'local',\n",
       " 'requir',\n",
       " 'us',\n",
       " '$',\n",
       " '1200',\n",
       " 'enabl',\n",
       " 'purchas',\n",
       " 'addit',\n",
       " 'stock',\n",
       " 'drug',\n",
       " 'integr',\n",
       " 'servic',\n",
       " 'mari',\n",
       " '43-years-old',\n",
       " 'marri',\n",
       " 'three',\n",
       " 'children',\n",
       " 'run',\n",
       " 'retail',\n",
       " 'shop',\n",
       " 'earn',\n",
       " 'live',\n",
       " 'oper',\n",
       " 'busi',\n",
       " 'four',\n",
       " 'year',\n",
       " 'retain',\n",
       " 'busi',\n",
       " 'good',\n",
       " 'custom',\n",
       " 'care',\n",
       " 'also',\n",
       " 'livestock',\n",
       " 'farm',\n",
       " 'supplement',\n",
       " 'incom',\n",
       " 'grate',\n",
       " 'faulu',\n",
       " 'kenya',\n",
       " 'abl',\n",
       " 'access',\n",
       " 'busi',\n",
       " 'loan',\n",
       " 'mari',\n",
       " 'hope',\n",
       " 'expand',\n",
       " 'busi',\n",
       " 'wholesal',\n",
       " 'oper',\n",
       " 'futur',\n",
       " 'request',\n",
       " '50',\n",
       " '000',\n",
       " 'kenya',\n",
       " 'shill',\n",
       " 'buy',\n",
       " 'cow',\n",
       " 'fatuma',\n",
       " 'widow',\n",
       " 'five',\n",
       " 'children',\n",
       " 'attend',\n",
       " 'school',\n",
       " 'famili',\n",
       " 'live',\n",
       " 'hous',\n",
       " 'neither',\n",
       " 'electr',\n",
       " 'pipe',\n",
       " 'water',\n",
       " 'oper',\n",
       " 'fish-sel',\n",
       " 'busi',\n",
       " 'past',\n",
       " 'year',\n",
       " 'sell',\n",
       " 'home',\n",
       " 'restaur',\n",
       " 'oper',\n",
       " 'passersbi',\n",
       " 'face',\n",
       " 'major',\n",
       " 'challeng',\n",
       " 'season',\n",
       " 'perish',\n",
       " 'lead',\n",
       " 'loss',\n",
       " 'ke',\n",
       " '10',\n",
       " '000',\n",
       " 'loan',\n",
       " 'want',\n",
       " 'purchas',\n",
       " 'bundl',\n",
       " 'fish',\n",
       " 'resal',\n",
       " 'dream',\n",
       " 'expand',\n",
       " 'busi',\n",
       " 'establish',\n",
       " 'anoth',\n",
       " 'busi',\n",
       " 'near',\n",
       " 'futur',\n",
       " 'thoma',\n",
       " '32',\n",
       " 'smallhold',\n",
       " 'farmer',\n",
       " 'resid',\n",
       " 'nyamira',\n",
       " 'agricultur',\n",
       " 'town',\n",
       " 'south',\n",
       " 'rift',\n",
       " 'region',\n",
       " 'kenya',\n",
       " 'arguabl',\n",
       " 'success',\n",
       " 'client',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'microfin',\n",
       " 'institut',\n",
       " 'deal',\n",
       " 'smallhold',\n",
       " 'farmer',\n",
       " 'rural',\n",
       " 'part',\n",
       " 'kenya',\n",
       " 'back',\n",
       " '2009',\n",
       " 'thoma',\n",
       " 'practic',\n",
       " 'tradit',\n",
       " 'farm',\n",
       " 'littl',\n",
       " 'knowledg',\n",
       " 'financ',\n",
       " 'half',\n",
       " 'acr',\n",
       " 'crop',\n",
       " 'maiz',\n",
       " 'per',\n",
       " 'season',\n",
       " 'return',\n",
       " 'meager',\n",
       " 'could',\n",
       " 'bare',\n",
       " 'surviv',\n",
       " 'kept',\n",
       " 'maiz',\n",
       " 'farm',\n",
       " 'year',\n",
       " 'without',\n",
       " 'turn',\n",
       " 'profit',\n",
       " '2013',\n",
       " 'switch',\n",
       " 'tomato',\n",
       " 'farm',\n",
       " 'light',\n",
       " 'end',\n",
       " 'tunnel',\n",
       " 'thoma',\n",
       " 'today',\n",
       " 'thoma',\n",
       " 'fully-fledg',\n",
       " 'entrepreneur',\n",
       " 'provid',\n",
       " 'technic',\n",
       " 'guidanc',\n",
       " 'train',\n",
       " 'program',\n",
       " 'exposur',\n",
       " 'visit',\n",
       " 'alreadi',\n",
       " 'servic',\n",
       " 'asset-bas',\n",
       " 'loan',\n",
       " 'fulli',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " '!',\n",
       " 'loan',\n",
       " 'acquir',\n",
       " 'numer',\n",
       " 'farm',\n",
       " 'suppli',\n",
       " 'capit',\n",
       " 'return',\n",
       " 'boom',\n",
       " 'tomato',\n",
       " 'farm',\n",
       " 'thoma',\n",
       " 'seek',\n",
       " 'loan',\n",
       " 'ke',\n",
       " '70',\n",
       " '000',\n",
       " 'build',\n",
       " 'greenhous',\n",
       " 'unlik',\n",
       " 'competit',\n",
       " 'thoma',\n",
       " 'use',\n",
       " 'modern',\n",
       " 'farm',\n",
       " 'techniqu',\n",
       " 'ensur',\n",
       " 'high',\n",
       " 'qualiti',\n",
       " 'produc',\n",
       " 'creat',\n",
       " 'name',\n",
       " 'demand',\n",
       " 'produc',\n",
       " 'lend',\n",
       " 'contribut',\n",
       " 'greatli',\n",
       " 'actual',\n",
       " 'thoma',\n",
       " \"'\",\n",
       " 'goal',\n",
       " 'expand',\n",
       " 'greenhous',\n",
       " 'futur',\n",
       " 'plan',\n",
       " 'start',\n",
       " 'export',\n",
       " 'produc',\n",
       " 'intern',\n",
       " 'market',\n",
       " 'inspir',\n",
       " 'make',\n",
       " 'loan',\n",
       " '!',\n",
       " 'johnson',\n",
       " 'marri',\n",
       " 'man',\n",
       " 'describ',\n",
       " 'focus',\n",
       " 'oper',\n",
       " 'farm',\n",
       " 'keep',\n",
       " 'cow',\n",
       " 'also',\n",
       " 'grow',\n",
       " 'potato',\n",
       " 'maiz',\n",
       " 'bean',\n",
       " 'involv',\n",
       " 'busi',\n",
       " 'six',\n",
       " 'year',\n",
       " 'busi',\n",
       " 'locat',\n",
       " 'good',\n",
       " 'area',\n",
       " 'primari',\n",
       " 'custom',\n",
       " 'local',\n",
       " 'describ',\n",
       " 'biggest',\n",
       " 'busi',\n",
       " 'challeng',\n",
       " 'inadequ',\n",
       " 'work',\n",
       " 'capit',\n",
       " 'use',\n",
       " 'ke',\n",
       " '20',\n",
       " '000',\n",
       " 'loan',\n",
       " 'buy',\n",
       " 'farm',\n",
       " 'input',\n",
       " 'jacklin',\n",
       " '35',\n",
       " 'year',\n",
       " 'old',\n",
       " '3',\n",
       " 'children',\n",
       " 'live',\n",
       " 'kokelo',\n",
       " 'villag',\n",
       " 'ndhiwa',\n",
       " 'kenya',\n",
       " 'jacklin',\n",
       " 'work',\n",
       " 'busi',\n",
       " 'owner',\n",
       " 'live',\n",
       " 'commun',\n",
       " 'kokelo',\n",
       " 'villag',\n",
       " 'access',\n",
       " 'clean',\n",
       " 'water',\n",
       " 'water',\n",
       " 'use',\n",
       " 'drink',\n",
       " 'cook',\n",
       " 'easili',\n",
       " 'contamin',\n",
       " 'bacteria',\n",
       " 'caus',\n",
       " 'diarrhea',\n",
       " 'water-born',\n",
       " 'diseas',\n",
       " 'jacklin',\n",
       " 'friendli',\n",
       " 'member',\n",
       " 'commun',\n",
       " 'elect',\n",
       " 'promot',\n",
       " 'villag',\n",
       " 'help',\n",
       " 'member',\n",
       " 'obtain',\n",
       " 'safe',\n",
       " 'drink',\n",
       " 'water',\n",
       " 'volunt',\n",
       " 'promot',\n",
       " 'jacklin',\n",
       " 'repres',\n",
       " 'commun',\n",
       " 'kiva',\n",
       " 'websit',\n",
       " 'educ',\n",
       " 'commun',\n",
       " 'protect',\n",
       " 'famili',\n",
       " 'unsaf',\n",
       " 'drink',\n",
       " 'water',\n",
       " 'use',\n",
       " 'chlorin',\n",
       " 'dispens',\n",
       " 'jacklin',\n",
       " '3',\n",
       " 'promot',\n",
       " 'commun',\n",
       " 'samuel',\n",
       " 'william',\n",
       " 'monica',\n",
       " 'need',\n",
       " 'loan',\n",
       " 'cover',\n",
       " 'cost',\n",
       " 'instal',\n",
       " 'maintain',\n",
       " 'chlorin',\n",
       " 'dispens',\n",
       " 'water',\n",
       " 'sourc',\n",
       " 'area',\n",
       " 'kiva',\n",
       " 'loan',\n",
       " 'repaid',\n",
       " 'evid',\n",
       " 'action',\n",
       " '(',\n",
       " 'www',\n",
       " 'evidenceact',\n",
       " 'org',\n",
       " ')',\n",
       " 'behalf',\n",
       " 'commun',\n",
       " 'sale',\n",
       " 'carbon',\n",
       " 'credit',\n",
       " 'use',\n",
       " 'chlorin',\n",
       " 'dispens',\n",
       " 'gener',\n",
       " 'carbon',\n",
       " 'credit',\n",
       " 'avoid',\n",
       " 'need',\n",
       " 'boil',\n",
       " 'water',\n",
       " 'make',\n",
       " 'safe',\n",
       " 'drink',\n",
       " 'revenu',\n",
       " 'sale',\n",
       " 'carbon',\n",
       " 'credit',\n",
       " 'organ',\n",
       " 'individu',\n",
       " 'want',\n",
       " 'reduc',\n",
       " 'carbon',\n",
       " 'footprint',\n",
       " 'use',\n",
       " 'repay',\n",
       " 'kiva',\n",
       " 'lender',\n",
       " 'also',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'jacklin',\n",
       " 'commun',\n",
       " 'access',\n",
       " 'safe',\n",
       " 'water',\n",
       " 'futur',\n",
       " 'dori',\n",
       " '30-year-old',\n",
       " 'proud',\n",
       " 'mother',\n",
       " 'six',\n",
       " 'children',\n",
       " 'group',\n",
       " 'leader',\n",
       " 'often',\n",
       " 'describ',\n",
       " 'experienc',\n",
       " 'farmer',\n",
       " 'repres',\n",
       " 'group',\n",
       " '13',\n",
       " 'farmer',\n",
       " 'bungoma',\n",
       " 'district',\n",
       " 'sinc',\n",
       " 'join',\n",
       " 'one',\n",
       " 'acr',\n",
       " 'fund',\n",
       " '2013',\n",
       " 'dori',\n",
       " 'notic',\n",
       " 'abl',\n",
       " 'consist',\n",
       " 'feed',\n",
       " 'famili',\n",
       " 'dori',\n",
       " 'describ',\n",
       " 'harvest',\n",
       " 'good',\n",
       " 'last',\n",
       " 'year',\n",
       " 'believ',\n",
       " 'better',\n",
       " 'one',\n",
       " 'year',\n",
       " 'continu',\n",
       " 'work',\n",
       " 'one',\n",
       " 'acr',\n",
       " 'fund',\n",
       " 'excit',\n",
       " 'also',\n",
       " 'purchas',\n",
       " 'solar',\n",
       " 'light',\n",
       " 'apart',\n",
       " 'fertil',\n",
       " 'maiz',\n",
       " 'abl',\n",
       " 'reduc',\n",
       " 'consumpt',\n",
       " 'paraffin',\n",
       " 'fuel',\n",
       " 'therefor',\n",
       " 'save',\n",
       " 'money',\n",
       " 'profit',\n",
       " 'season',\n",
       " 'harvest',\n",
       " 'plan',\n",
       " 'buy',\n",
       " 'cow',\n",
       " 'loan',\n",
       " 'doriss',\n",
       " 'group',\n",
       " 'abl',\n",
       " 'plant',\n",
       " 'total',\n",
       " 'six',\n",
       " 'acr',\n",
       " 'land',\n",
       " 'purchas',\n",
       " 'total',\n",
       " 'nine',\n",
       " 'solar',\n",
       " 'light',\n",
       " 'karisa',\n",
       " '62-year-old',\n",
       " 'tailor',\n",
       " 'tsangatsini',\n",
       " 'mariakani',\n",
       " 'marri',\n",
       " 'father',\n",
       " 'four',\n",
       " 'children',\n",
       " 'busi',\n",
       " 'past',\n",
       " '35',\n",
       " 'year',\n",
       " 'great',\n",
       " 'introduc',\n",
       " 'kadet',\n",
       " 'ltd',\n",
       " 'mark',\n",
       " 'third',\n",
       " 'loan',\n",
       " 'financ',\n",
       " 'busi',\n",
       " 'plan',\n",
       " 'expand',\n",
       " 'busi',\n",
       " 'purchas',\n",
       " 'cloth',\n",
       " 'materi',\n",
       " 'use',\n",
       " 'anticip',\n",
       " 'profit',\n",
       " 'educ',\n",
       " 'children',\n",
       " 'erad',\n",
       " 'poverti',\n",
       " 'hope',\n",
       " 'excel',\n",
       " 'busi',\n",
       " 'disma',\n",
       " '52',\n",
       " 'year',\n",
       " 'old',\n",
       " 'often',\n",
       " 'refer',\n",
       " 'realli',\n",
       " 'hardwork',\n",
       " 'individu',\n",
       " 'group',\n",
       " 'leader',\n",
       " 'repres',\n",
       " 'group',\n",
       " 'webuy',\n",
       " 'district',\n",
       " 'form',\n",
       " '12',\n",
       " 'farmer',\n",
       " 'includ',\n",
       " 'disma',\n",
       " 'farmer',\n",
       " '30',\n",
       " 'year',\n",
       " 'work',\n",
       " 'one',\n",
       " 'acr',\n",
       " 'fund',\n",
       " 'join',\n",
       " 'first',\n",
       " 'time',\n",
       " '2010',\n",
       " 'want',\n",
       " 'earn',\n",
       " 'enough',\n",
       " 'send',\n",
       " 'children',\n",
       " 'school',\n",
       " 'get',\n",
       " 'maiz',\n",
       " 'seed',\n",
       " 'fertil',\n",
       " 'loan',\n",
       " 'also',\n",
       " 'solar',\n",
       " 'light',\n",
       " 'order',\n",
       " 'light',\n",
       " 'dark',\n",
       " 'hour',\n",
       " 'children',\n",
       " 'abl',\n",
       " 'studi',\n",
       " 'decid',\n",
       " 'use',\n",
       " 'profit',\n",
       " 'gain',\n",
       " 'year',\n",
       " 'harvest',\n",
       " 'invest',\n",
       " 'busi',\n",
       " 'loan',\n",
       " 'dismass',\n",
       " 'group',\n",
       " 'receiv',\n",
       " 'total',\n",
       " '6',\n",
       " 'solar',\n",
       " 'light',\n",
       " 'well',\n",
       " 'farm',\n",
       " 'input',\n",
       " 'plant',\n",
       " 'total',\n",
       " '8',\n",
       " '25',\n",
       " 'acr',\n",
       " '``',\n",
       " 'esha',\n",
       " 'marri',\n",
       " 'woman',\n",
       " 'five',\n",
       " 'children',\n",
       " 'attend',\n",
       " 'school',\n",
       " 'own',\n",
       " 'hous',\n",
       " 'electr',\n",
       " 'pipe',\n",
       " 'water',\n",
       " 'greatest',\n",
       " 'monthli',\n",
       " 'expens',\n",
       " 'school',\n",
       " 'fee',\n",
       " 'past',\n",
       " 'three',\n",
       " 'year',\n",
       " 'oper',\n",
       " 'firewood-sel',\n",
       " 'busi',\n",
       " 'sell',\n",
       " 'home',\n",
       " 'neighbor',\n",
       " 'addit',\n",
       " 'also',\n",
       " 'oper',\n",
       " 'veget',\n",
       " 'stall',\n",
       " 'provid',\n",
       " 'anoth',\n",
       " 'sourc',\n",
       " 'incom',\n",
       " 'face',\n",
       " 'major',\n",
       " 'challeng',\n",
       " 'high',\n",
       " 'cost',\n",
       " 'transport',\n",
       " 'busi',\n",
       " 'dream',\n",
       " 'expand',\n",
       " 'busi',\n",
       " 'becom',\n",
       " 'self-reli',\n",
       " 'futur',\n",
       " 'ksh',\n",
       " '40',\n",
       " '000',\n",
       " 'want',\n",
       " 'purchas',\n",
       " 'bundl',\n",
       " 'firewood',\n",
       " 'sack',\n",
       " 'green',\n",
       " 'veget',\n",
       " 'resal',\n",
       " 'decid',\n",
       " 'join',\n",
       " 'yehu',\n",
       " 'access',\n",
       " 'loan',\n",
       " 'boost',\n",
       " 'busi',\n",
       " 'grace',\n",
       " 'run',\n",
       " 'pegra',\n",
       " 'auto',\n",
       " 'spare',\n",
       " 'hardwar',\n",
       " 'sell',\n",
       " 'spare',\n",
       " 'part',\n",
       " 'mechan',\n",
       " 'last',\n",
       " 'year',\n",
       " 'one',\n",
       " 'employe',\n",
       " 'busi',\n",
       " 'challeng',\n",
       " 'lack',\n",
       " 'fund',\n",
       " 'strong',\n",
       " 'competit',\n",
       " 'use',\n",
       " 'loan',\n",
       " '20',\n",
       " '000',\n",
       " 'kenyan',\n",
       " 'shill',\n",
       " 'buy',\n",
       " 'spare',\n",
       " 'part',\n",
       " 'futur',\n",
       " 'want',\n",
       " 'supplier',\n",
       " 'contain',\n",
       " 'auto',\n",
       " 'spare',\n",
       " 'part',\n",
       " 'grace',\n",
       " 'marri',\n",
       " 'seven',\n",
       " 'children',\n",
       " 'describ',\n",
       " 'person',\n",
       " 'good',\n",
       " 'moral',\n",
       " 'dedic',\n",
       " 'work',\n",
       " 'paul',\n",
       " '41-year-old',\n",
       " 'farmer',\n",
       " 'live',\n",
       " 'litein',\n",
       " 'wife',\n",
       " '3',\n",
       " 'children',\n",
       " 'school-go',\n",
       " 'age',\n",
       " 'farm',\n",
       " '4',\n",
       " 'year',\n",
       " 'produc',\n",
       " 'sell',\n",
       " 'tea',\n",
       " 'milk',\n",
       " 'egg',\n",
       " 'farm',\n",
       " 'love',\n",
       " 'mostli',\n",
       " 'tea',\n",
       " 'dairi',\n",
       " 'farm',\n",
       " 'well',\n",
       " 'litein',\n",
       " 'challeng',\n",
       " 'face',\n",
       " 'unpredict',\n",
       " 'climat',\n",
       " 'condit',\n",
       " 'paul',\n",
       " 'chose',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'loan',\n",
       " 'offer',\n",
       " 'friendli',\n",
       " 'servic',\n",
       " 'custom',\n",
       " 'loan',\n",
       " 'lower',\n",
       " 'interest',\n",
       " 'rate',\n",
       " 'juhudi',\n",
       " 'kilimo',\n",
       " 'help',\n",
       " 'farmer',\n",
       " 'manag',\n",
       " 'asset',\n",
       " 'add',\n",
       " 'incom',\n",
       " 'loan',\n",
       " 'construct',\n",
       " 'greenhous',\n",
       " 'thu',\n",
       " 'varieti',\n",
       " 'plant',\n",
       " 'gener',\n",
       " 'incom',\n",
       " 'improv',\n",
       " 'famili',\n",
       " \"'s\",\n",
       " 'live',\n",
       " 'standard',\n",
       " 'educ',\n",
       " 'children',\n",
       " 'maureen',\n",
       " '34',\n",
       " 'three',\n",
       " 'school-go',\n",
       " 'children',\n",
       " 'past',\n",
       " 'three',\n",
       " 'year',\n",
       " 'manag',\n",
       " 'oper',\n",
       " 'tailor',\n",
       " 'busi',\n",
       " 'learn',\n",
       " 'skill',\n",
       " 'attend',\n",
       " 'tailor',\n",
       " 'dressmak',\n",
       " 'colleg',\n",
       " 'one',\n",
       " 'villag',\n",
       " 'poly-techniqu',\n",
       " 'buy',\n",
       " 'cloth',\n",
       " 'materi',\n",
       " 'citi',\n",
       " 'eastern',\n",
       " 'part',\n",
       " 'countri',\n",
       " 'maureen',\n",
       " 'seek',\n",
       " 'loan',\n",
       " 'purchas',\n",
       " 'roll',\n",
       " 'cloth',\n",
       " 'make',\n",
       " 'fashion',\n",
       " 'cloth',\n",
       " 'want',\n",
       " 'make',\n",
       " 'improv',\n",
       " 'display',\n",
       " 'attract',\n",
       " 'custom',\n",
       " 'increas',\n",
       " 'incom',\n",
       " 'underli',\n",
       " 'goal',\n",
       " 'abl',\n",
       " 'provid',\n",
       " 'children',\n",
       " 'everyth',\n",
       " 'need',\n",
       " 'loic',\n",
       " 'marri',\n",
       " 'woman',\n",
       " 'four',\n",
       " 'children',\n",
       " 'graduat',\n",
       " 'school',\n",
       " 'own',\n",
       " 'hous',\n",
       " 'electr',\n",
       " 'pipe',\n",
       " 'water',\n",
       " 'greatest',\n",
       " 'monthli',\n",
       " 'expens',\n",
       " 'food',\n",
       " 'electr',\n",
       " 'bill',\n",
       " 'cloth',\n",
       " '20',\n",
       " 'year',\n",
       " 'oper',\n",
       " 'restaur',\n",
       " 'sell',\n",
       " 'neighbor',\n",
       " 'market',\n",
       " 'dweller',\n",
       " 'face',\n",
       " 'major',\n",
       " 'challeng',\n",
       " 'competit',\n",
       " 'restaur',\n",
       " 'oper',\n",
       " 'area',\n",
       " 'loic',\n",
       " 'dream',\n",
       " 'establish',\n",
       " 'plot',\n",
       " 'futur',\n",
       " 'request',\n",
       " 'ksh',\n",
       " '20',\n",
       " '000',\n",
       " 'purchas',\n",
       " 'construct',\n",
       " 'materi',\n",
       " 'cement',\n",
       " 'repair',\n",
       " 'restaur',\n",
       " 'loic',\n",
       " 'decid',\n",
       " 'join',\n",
       " 'yehu',\n",
       " 'access',\n",
       " 'loan',\n",
       " 'boost',\n",
       " 'busi',\n",
       " 'monica',\n",
       " 'singl',\n",
       " 'woman',\n",
       " '2',\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data - stem\n",
    "# Porter stemmer is one of several\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in text_corpus_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67717"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4727"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of words in of entire corpus \n",
    "len(text_corpus_clean)\n",
    "\n",
    "# number of unique words in entire corpus\n",
    "len(set(text_corpus_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm: K-Means Clustering\n",
    "\n",
    "Here, we apply k-means clustering to the documents. We use scikit-learn to tf-idf regularize each word in the documents, and then cluster the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x2113 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 75700 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "\n",
    "# Notes on parameters defined below:\n",
    "#  max_df: this is the maximum frequency within the documents a given feature can have to be \n",
    "#        used in the tfi-idf matrix. If the term is in greater than 80% of the documents it \n",
    "#        probably cares little meanining (in the context of film synopses)\n",
    "#  min_idf: this could be an integer (e.g. 5) and the term would have to be in at least 5 of \n",
    "#        the documents to be considered. Here I pass 0.01; the term must be in at least 1% of \n",
    "#        the document as each document is comparatively short. \n",
    "#  ngram_range: this just means I'll look at unigrams, bigrams and trigrams. \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, ngram_range=(1,3))\n",
    "\n",
    " #fit the vectorizer to text that is still in sentences\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=6, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "k = 6\n",
    "model = KMeans(n_clusters = k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " business\n",
      " electricity\n",
      " school\n",
      " selling\n",
      " wants purchase\n",
      " piped\n",
      " piped water\n",
      " yehu\n",
      " house electricity\n",
      " electricity piped water\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:\n",
      " business\n",
      " describes\n",
      " primary customers\n",
      " business located\n",
      " involved business\n",
      " customers\n",
      " biggest business\n",
      " use kes\n",
      " biggest business challenge\n",
      " operates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2:\n",
      " farming\n",
      " farm\n",
      " dairy\n",
      " income\n",
      " milk\n",
      " kiva\n",
      " poultry\n",
      " juhudi\n",
      " family\n",
      " kilimo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3:\n",
      " business\n",
      " years\n",
      " kenya\n",
      " 000\n",
      " old\n",
      " children\n",
      " years old\n",
      " kes\n",
      " buy\n",
      " income\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4:\n",
      " kadet\n",
      " business\n",
      " years\n",
      " old\n",
      " loan kadet\n",
      " use\n",
      " plans\n",
      " hopes\n",
      " years old\n",
      " introduced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5:\n",
      " group\n",
      " acre\n",
      " acre fund\n",
      " fund\n",
      " total\n",
      " solar\n",
      " farmers\n",
      " light\n",
      " receive\n",
      " solar light\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" % i,)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind],)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fascinating -- each cluster corresponds to some big partners that we saw in earlier notebooks, namely Faulu, One Acre Fund, Juhudi, Yehu and VisionFund Kenya (formerly known as Kadet.) Each partner also appears to specialize in certain types of loans (e.g., Juhudi helps fund farming/dairy/poultry loans.) Let's refresh our memory of the top partners by loan amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partner_name\n",
       "VisionFund Kenya                                                            11351650\n",
       "One Acre Fund                                                                8026025\n",
       "Yehu Microfinance Trust                                                      7631100\n",
       "Juhudi Kilimo                                                                7493275\n",
       "SMEP Microfinance Bank                                                       6738200\n",
       "Faulu Kenya                                                                  2892775\n",
       "Milango Financial Services                                                   1378975\n",
       "Hand in Hand Eastern Africa                                                   988825\n",
       "Kenya ECLOF                                                                   851175\n",
       "Evidence Action                                                               799950\n",
       "Ebony Foundation (Eb-F)                                                       697975\n",
       "Women`s Economic Empowerment Consort (WEEC)                                   449075\n",
       "KOMAZA                                                                        443475\n",
       "K-Met Savings and Credit Cooperative Ltd                                      361650\n",
       "Honey Care Africa                                                             258075\n",
       "Sanergy                                                                       222575\n",
       "Burn Manufacturing                                                            183100\n",
       "Opportunity International- Wedco Ltd.                                         155375\n",
       "Visionary Empowerment Programme                                               150625\n",
       "Action Now: Kenya (ANK)                                                       127300\n",
       "Digital Divide Data (DDD)                                                     114500\n",
       "People Microcredit Investment Bureau (PEMCI)                                  111550\n",
       "iSmart Kenya                                                                  109700\n",
       "Supporting Enterprises for Economic Development (SEED Development Group)       74550\n",
       "Motorbank Kenya                                                                71900\n",
       "Nuru International                                                             70650\n",
       "Takamoto Biogas                                                                59850\n",
       "Asante Kenya Foundation                                                        49800\n",
       "Moringa School                                                                 49550\n",
       "Housing Finance Foundation                                                     41975\n",
       "EcoZoom                                                                        41775\n",
       "Junior Achievement Kenya                                                       35525\n",
       "Strathmore University                                                          33625\n",
       "Grameen Foundation AppLab                                                      22500\n",
       "Paradigm Project                                                               17625\n",
       "SPIRE Education                                                                17050\n",
       "BrazAfric                                                                      16300\n",
       "One Degree Solar                                                               16000\n",
       "PowerGen Renewable Energy                                                       9400\n",
       "Living Goods                                                                    3950\n",
       "Name: loan_amount, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partners = df.groupby(['partner_name'])['loan_amount'].sum()\n",
    "partners.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "What other clusters do you see? Try adjusting the number of clusters (i.e. the hyperparameter \"k\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
