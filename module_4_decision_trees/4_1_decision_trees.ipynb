{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.1:  Decision Trees\n",
    "\n",
    "Decision trees can be used for either regression or classification tasks. Decision trees are a powerful tool; however, are very prone to overfitting the training dataset and therefore often fail to generalize well to test data sets. However, they are the building block for several other powerful machine learning algorithms and are therefore important to learn about.\n",
    "\n",
    "<img src=\"../images/DecisionTreeExample.png\" alt=\"Drawing\" style=\"width: 500px;height=500\"/>\n",
    "\n",
    "Here's a look ahead at what we'll be doing in this notebook:\n",
    "\n",
    "\n",
    "1. [Load data and packages](#loaddata)\n",
    "    \n",
    "Then we will work incrementally from Decision Trees to Random Forests. At each stage we will experiment with tuning the model parameters and evaluate the models performance.\n",
    "2. [Build Decision Tree](#decisiontree)\n",
    "\n",
    "3. [Feature Importance](#featureimportance)\n",
    "\n",
    "As a reminder our previous model, Linear regression, was a parametric model with assumes linearity among others.\n",
    "\n",
    "Whereas decision trees and associated algorithms are non-parametric models which means we are no longer restricted to independant variables which have a linear relationship and we don't have to ensure several assumptions are true. \n",
    "\n",
    "Therefore we can start to bring in other features that could be useful.\n",
    "\n",
    "After we run our decision trees, we will compare our new output to our output from the linear regressions we ran in the previous notebook. \n",
    "\n",
    "In this notebook, we will be looking at how we can predict the loan amount using decision trees. However, it is worth mentioning that these methods can also be used to classify data, for example some interesting classification questions we could investigate are:\n",
    "- Can we classify which loans expired and which one got funded?\n",
    "- Is a loan posted by a male or female?\n",
    "\n",
    "Feel free to investigate these on your own time! Here is a very simple example of how the RandomForestClassifier works: https://bicorner.com/2015/10/26/random-forest-using-ipython/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import packages\n",
    "<a id='loaddata'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rosina/anaconda2/lib/python2.7/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/home/rosina/anaconda2/lib/python2.7/site-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/home/rosina/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ggplot import *\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import graphviz \n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have graphviz installed or are having problems displaying the tree structure later on, try:\n",
    "- brew install graphviz (Mac/Windows)\n",
    "- sudo apt-get install graphviz (Linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data to pandas DataFrame\n",
    "data_path = '../data/'\n",
    "df = pd.read_csv(data_path+'df_end_of_linear.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Remove this part and incorporate it into feature engineering section.\n",
    "# potentially the feature engineering section should show how to do one hot encoding and this module\n",
    "# will reference one hot encoding and remove any cols that are strings to highligh that sklearn's implementation\n",
    "# cannot handle strings.\n",
    "df = df.dropna()\n",
    "cols = df[['loan_amount', \n",
    "           'partner_delinquency_rate',\n",
    "            'posted_year',\n",
    "           'posted_month',\n",
    "           'female',\n",
    "           'num_tags',\n",
    "           'parent',\n",
    "           'tag_#Woman Owned Biz',\n",
    "           'age_int',\n",
    "           'tag_#Repeat Borrower',\n",
    "           'children_int',\n",
    "          'more_one_partner_country',\n",
    "          'terms.repayment_term',\n",
    "           'tag_#Schooling',\n",
    "           'married',\n",
    "           'pct_female',\n",
    "           'exploratory_partner',\n",
    "           'partner_dollar_amount',\n",
    "           'top_partner_id',\n",
    "           'num_partner_countries',\n",
    "           'days_to_fund',\n",
    "            'hours_to_fund',\n",
    "            'bc_partner_others',\n",
    "           'bc_partner_HIHEA',\n",
    "           'bc_partner_OAF_high',\n",
    "           'bc_partner_OAF_low',\n",
    "         'sector_Personal Use',\n",
    "           'sector_Health',\n",
    "           'sector_Wholesale',\n",
    "           'sector_Agriculture',\n",
    "           'kids']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like last module, we are going to build regressors to predict the loan amount.\n",
    "\n",
    "However, instead of using just a few features, we will build a tree that considers many the features in the dataset - including those we have engineered ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['loan_amount']\n",
    "# drop returns a copy of the DataFrame with the specified columns removed.  \n",
    "X = cols.drop('loan_amount', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets;\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Decision Tree\n",
    "<a id='decisiontree'></a>\n",
    "Before we build our first decision tree, let's first learn about the input parameters for sklearn's implementation of a Decision Tree Regressor.  \n",
    "\n",
    "Feel free to look at the [docs](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.get_params), or simply put a question mark before a call to the class.  Prepending a ? to any method, variable, or class will display that method's defined docstring (way to go ipython!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the sklearn algorithms are implemented using the same standard steps: \n",
    "- **Step 1: Initiate the algorithm** Tdefine the parameters (& hyperparameters of the algorithm) of the algorithm. For example, the maximum depth, the minimum samples in a leaf etc. To learn more about the parameters for each algorithm, either check the module documentation on the internet or run a cell with the algorithm name followed by ? as we did at the beginning of this notebook for the RandomForestRegressor. These resources will also tell you the default values used for each parameter. \n",
    "\n",
    "- **Step 2: Train the algorithm** train the algorithm by fitting it to the X_train and y_train datasets.\n",
    "\n",
    "- **Step 3: Evaluating the algorithm** evaluate the predictive power of the algorithm by comparing the predictive loan amount values to the true values. We can do this for the training and testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let build a function which encapsulates the 3 model implementation steps; Initialize, Train, Evaluate our decision tree regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_score_regressor(sklearn_regressor, X_train, y_train, X_test, y_test, model_parameters):\n",
    "    '''\n",
    "    Purpose: \n",
    "        - train a regressor on training data\n",
    "        - score data on training and test data\n",
    "        - return trained model\n",
    "    '''\n",
    "    # Step 1: Initializing the sklearn regressor \n",
    "    regressor = sklearn_regressor(**model_parameters)\n",
    "    # Step 2: Training the algorithm using the X_train dataset of features and y_train, the associated target features\n",
    "    regressor.fit(X_train, y_train)\n",
    "    # Step 3: Calculating the score of the predictive power on the training and testing dataset.\n",
    "    training_score = regressor.score(X_train, y_train)\n",
    "    testing_score = regressor.score(X_test, y_test)\n",
    "    # Print the results!\n",
    "    print(\"Train score: \" + str(training_score))\n",
    "    print(\"Test score: \" + str(testing_score))\n",
    "        \n",
    "    return regressor\n",
    "?train_score_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all tree algorithms the major challenge is using the parameters to balance the bias vs variance tradeoff.  \n",
    "\n",
    "Before we get into exploring the parameters, let's see how the model preforms when using the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.363635374266\n"
     ]
    }
   ],
   "source": [
    "trained_regressor = train_score_regressor(sklearn_regressor = DecisionTreeRegressor,\n",
    "                                          X_train = X_train, y_train = y_train, \n",
    "                                          X_test = X_test, y_test = y_test, \n",
    "                                          model_parameters = {'random_state':42})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Decision Tree managed to get a perfect r2 scored on the training data, it managed an abysmal .34 on the test data.  This is a clear indication that the model has overfit the data.\n",
    "\n",
    "Given that by default sklearn's implementation of a DecisionTreeRegressor does not put any restrictions on the depth of the tree, the number of samples per leaf, the number of samples per leaf, etc.  As a result, the Decision Tree will find signal in any and all noise of the training data set, which causes the model to perform poorly on the test data.  \n",
    "\n",
    "When a model overfits to a training data set, we say it has **high variance**.  Since an unconstrained decision tree will almost perfectly model any training data, it will vary tremendously depending on the training data that is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Parameter tuning\n",
    "To reduce the variance, we constrain the model using some of the provided parameters for example:\n",
    "- Criterion (Cost function used to measure the purity of a split)\n",
    "- Maximum depth of the tree\n",
    "- Minimum samples for each node split\n",
    "- Minimum samples for each terminal node\n",
    "- Maximum number of terminal nodes\n",
    "\n",
    "If you need a refresher to remember what these parameters are, look back over the [slides](https://docs.google.com/presentation/d/1leWPbwis9GJHJcQehlhPhtKEAErUPvlTpKjnkv1aWWU/edit?usp=sharing) or use this [useful blog](https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/#four).\n",
    "\n",
    "Initially, we are going to experiment with the max_depth parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.558032781957\n",
      "Test score: 0.438339906714\n"
     ]
    }
   ],
   "source": [
    "# Define the model parameters \n",
    "# We are fixing the random state so that the results are reproducible.\n",
    "parameters = {\"max_depth\":4,'random_state':42}\n",
    "trained_regressor = train_score_regressor(sklearn_regressor = DecisionTreeRegressor,\n",
    "                                          X_train = X_train, y_train = y_train, \n",
    "                                          X_test = X_test, y_test = y_test, \n",
    "                                          model_parameters = {\"max_depth\":4,'random_state':42})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
