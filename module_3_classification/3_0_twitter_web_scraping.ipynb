{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "def pull_tweets (query, maxTweets = 1000, tweetsPerQuery = 100, max_id = -1, sinceId = None):\n",
    "    '''\n",
    "    Finds tweets (Comment, Date, Favorites, User) for a query string.\n",
    "    Twitter API limit per query is 100. Combines these queries. \n",
    "    '''\n",
    "    \n",
    "    # Fill with your own app details\n",
    "    API_KEY = \"wCl2jflXpyWmYDM22iKFsaiS2\"\n",
    "    API_SEC = \"f3DkCao13uCfA58bSQXahsDVNF5qzNztrgt3wB2RDDAV8zyXvT\"\n",
    "    \n",
    "    # connect to Twitter using authentication\n",
    "    auth = tweepy.AppAuthHandler(API_KEY, API_SEC)\n",
    "    # wait_on_rate_limit means that if the API limit is hit, \n",
    "    #   the pulls will wait until more calls are available\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    # Pull comments from Twitter\n",
    "    # See https://developer.twitter.com/en/docs/tweets/timelines/guides/working-with-timelines\n",
    "    tweetCount = 0\n",
    "    data = pd.DataFrame() \n",
    "    \n",
    "    while tweetCount < maxTweets:\n",
    "        if (max_id <= 0):\n",
    "            new_tweets = api.search(q=query, count=tweetsPerQuery, \n",
    "                                    since_id=sinceId)\n",
    "        else:\n",
    "            new_tweets = api.search(q=query, count=tweetsPerQuery,\n",
    "                                    max_id=str(max_id - 1), \n",
    "                                    since_id=sinceId)\n",
    "        if not new_tweets:\n",
    "            print(\"No more tweets found\")\n",
    "            break\n",
    "    \n",
    "        tweetCount += len(new_tweets)\n",
    "        print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "        max_id = new_tweets[-1].id\n",
    "                    \n",
    "        ## Create a dataset from the downloaded tweets\n",
    "        new_data = pd.DataFrame([{\n",
    "                'Date': tweet.created_at,\n",
    "                'Comments': tweet.text, \n",
    "                'User': tweet.user.name, \n",
    "                'Favorites': tweet.favorite_count} \n",
    "                for tweet in new_tweets])\n",
    "          \n",
    "        data = data.append(new_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 32 tweets\n",
      "Downloaded 57 tweets\n",
      "Downloaded 104 tweets\n",
      "Downloaded 143 tweets\n",
      "Downloaded 215 tweets\n",
      "Downloaded 315 tweets\n",
      "Downloaded 413 tweets\n",
      "Downloaded 500 tweets\n",
      "Downloaded 591 tweets\n",
      "Downloaded 677 tweets\n",
      "Downloaded 743 tweets\n",
      "Downloaded 824 tweets\n",
      "Downloaded 890 tweets\n",
      "Downloaded 953 tweets\n",
      "Downloaded 990 tweets\n",
      "Downloaded 1052 tweets\n",
      "Downloaded 1121 tweets\n",
      "Downloaded 1155 tweets\n",
      "Downloaded 1255 tweets\n",
      "Downloaded 1341 tweets\n",
      "Downloaded 1441 tweets\n",
      "Downloaded 1541 tweets\n",
      "Downloaded 1641 tweets\n",
      "Downloaded 1741 tweets\n",
      "Downloaded 1841 tweets\n",
      "Downloaded 1941 tweets\n",
      "Downloaded 2041 tweets\n",
      "Downloaded 2141 tweets\n",
      "Downloaded 2241 tweets\n",
      "Downloaded 2341 tweets\n",
      "Downloaded 2441 tweets\n",
      "Downloaded 2541 tweets\n",
      "Downloaded 2641 tweets\n",
      "Downloaded 2741 tweets\n",
      "Downloaded 2841 tweets\n",
      "Downloaded 2941 tweets\n",
      "Downloaded 3041 tweets\n",
      "Downloaded 3141 tweets\n",
      "Downloaded 3241 tweets\n",
      "No more tweets found\n"
     ]
    }
   ],
   "source": [
    "data = pull_tweets(\"microfinance\", maxTweets = 5000)\n",
    "\n",
    "# In real life you might have test data with pre-labeled sentiments. We will use a simple word net algorithm to classify for now.\n",
    "data['Polarity'] = [TextBlob(comment).polarity for comment in data.Comments]\n",
    "\n",
    "data.loc[data['Polarity'] > 0, 'Sentiment'] = 'positive'\n",
    "data.loc[data['Polarity'] < 0, 'Sentiment'] = 'negative'\n",
    "data.loc[data['Polarity'] == 0, 'Sentiment'] = 'neutral'\n",
    "\n",
    "#convert data to a csv\n",
    "data.to_csv(\"microfinance_tweets.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
